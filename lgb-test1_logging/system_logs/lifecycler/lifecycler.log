2022-01-18T13:45:09.795579Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=origin/0181881dfa996f7d819c0ab9a2ebba1281777791 ci_number=20220112.2 ci_name=CommonRuntime-prod-build build_time=2022-01-12 22:49:36.037858
2022-01-18T13:45:09.795833Z  INFO load_config_from_env:load_capability_addresses_from_env: lifecycler::config: loaded capability address for CS_CAPABILITY cap_name=CS_CAPABILITY address=/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/cs-capability:0
2022-01-18T13:45:09.795860Z  INFO load_config_from_env:load_capability_addresses_from_env: lifecycler::config: loaded capability address for HOSTTOOLS_CAPABILITY cap_name=HOSTTOOLS_CAPABILITY address=/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/hosttools-capability:0
2022-01-18T13:45:09.795884Z  INFO load_config_from_env:load_capability_addresses_from_env: lifecycler::config: close time.busy=146µs time.idle=5.50µs
2022-01-18T13:45:09.795906Z  INFO load_config_from_env: lifecycler::config: close time.busy=265µs time.idle=9.40µs
2022-01-18T13:45:09.795996Z  INFO Lifecycler::run_service{distributed_state_sender=None}: lifecycler::service: serving lifecycle service address=/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/lifecycler:0
2022-01-18T13:45:09.796065Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/cs-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:09.796174Z  INFO Lifecycler::run_service{distributed_state_sender=None}:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/lifecycler:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2022-01-18T13:45:16.380873Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/cs-capability:0")
2022-01-18T13:45:16.380988Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=38.9ms time.idle=6.55s
2022-01-18T13:45:16.381172Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/cs-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:16.381403Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/cs-capability:0")
2022-01-18T13:45:16.383207Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=1.98ms time.idle=56.8µs
2022-01-18T13:45:16.387463Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/cs-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:16.387712Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/cs-capability:0")
2022-01-18T13:45:16.388011Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=504µs time.idle=48.3µs
2022-01-18T13:45:16.388038Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:ensure_service_healthy: lifecycler::health_monitor: Ensuring health service_name=CS_CAPABILITY
2022-01-18T13:45:16.391426Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:ensure_service_healthy: lifecycler::health_client: Health status for service service_name=CS_CAPABILITY health_status=1
2022-01-18T13:45:16.391458Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:ensure_service_healthy: lifecycler::health_monitor: Service is healthy service_name=CS_CAPABILITY
2022-01-18T13:45:16.391474Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:ensure_service_healthy: lifecycler::health_monitor: close time.busy=160µs time.idle=3.28ms
2022-01-18T13:45:16.391611Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/hosttools-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:16.391800Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/hosttools-capability:0")
2022-01-18T13:45:16.391832Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=214µs time.idle=9.60µs
2022-01-18T13:45:16.392042Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/hosttools-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:16.392284Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/hosttools-capability:0")
2022-01-18T13:45:16.392336Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=203µs time.idle=94.3µs
2022-01-18T13:45:16.392423Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/hosttools-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:16.392596Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/hosttools-capability:0")
2022-01-18T13:45:16.392628Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=205µs time.idle=3.40µs
2022-01-18T13:45:16.392665Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:ensure_service_healthy: lifecycler::health_monitor: Ensuring health service_name=HOSTTOOLS_CAPABILITY
2022-01-18T13:45:16.393190Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:ensure_service_healthy: lifecycler::health_client: Health status for service service_name=HOSTTOOLS_CAPABILITY health_status=1
2022-01-18T13:45:16.393223Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:ensure_service_healthy: lifecycler::health_monitor: Service is healthy service_name=HOSTTOOLS_CAPABILITY
2022-01-18T13:45:16.393238Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:ensure_service_healthy: lifecycler::health_monitor: close time.busy=157µs time.idle=418µs
2022-01-18T13:45:16.393261Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities: lifecycler::lifecycle: close time.busy=49.8ms time.idle=6.55s
2022-01-18T13:45:16.394076Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="HOSTTOOLS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=HOSTTOOLS_CAPABILITY
2022-01-18T13:45:16.394118Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="HOSTTOOLS_CAPABILITY"}: lifecycler::capability_client: close time.busy=168µs time.idle=591µs
2022-01-18T13:45:16.864928Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="CS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=CS_CAPABILITY
2022-01-18T13:45:16.864987Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="CS_CAPABILITY"}: lifecycler::capability_client: close time.busy=171µs time.idle=472ms
2022-01-18T13:45:16.865037Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities: lifecycler::lifecycle: close time.busy=426µs time.idle=471ms
2022-01-18T13:45:16.865180Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:34.996424Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/executor:0")
2022-01-18T13:45:34.996480Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: close time.busy=92.3ms time.idle=18.0s
2022-01-18T13:45:34.996510Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: lifecycler::executor_client: close time.busy=95.1ms time.idle=18.0s
2022-01-18T13:45:34.996619Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:34.996767Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/executor:0")
2022-01-18T13:45:34.996800Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: close time.busy=175µs time.idle=8.50µs
2022-01-18T13:45:34.996814Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: lifecycler::executor_client: close time.busy=284µs time.idle=9.60µs
2022-01-18T13:45:34.996879Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 86400s }
2022-01-18T13:45:34.997033Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/.grpc/executor:0")
2022-01-18T13:45:34.997083Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: close time.busy=142µs time.idle=64.9µs
2022-01-18T13:45:34.997129Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:ensure_service_healthy: lifecycler::health_monitor: Ensuring health service_name=Executor
2022-01-18T13:45:34.997750Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:ensure_service_healthy: lifecycler::health_client: Health status for service service_name=Executor health_status=1
2022-01-18T13:45:34.998911Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:ensure_service_healthy: lifecycler::health_monitor: Service is healthy service_name=Executor
2022-01-18T13:45:34.998940Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:ensure_service_healthy: lifecycler::health_monitor: close time.busy=1.30ms time.idle=514µs
2022-01-18T13:45:35.003244Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor: lifecycler::lifecycle: close time.busy=105ms time.idle=18.0s
2022-01-18T13:45:35.003304Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: entering phase rank=None phase=0
2022-01-18T13:45:35.003336Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:barrier_sync: lifecycler::lifecycle: close time.busy=800ns time.idle=2.50µs
2022-01-18T13:45:35.003383Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: starting phase execution rank=None phase=0
2022-01-18T13:45:35.003977Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: executing phase commands rank=None phase=0
2022-01-18T13:45:35.003995Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands: lifecycler::executor_client: Executing commands
2022-01-18T13:45:35.004372Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands:executor_client::start_execution{commands_f=Command(Command { executable: Spawn(Spawn { program: "/azureml-envs/azureml_08f74657c3f2d3647b16ec4c255a28d8/bin/python", args: Some(["-c", "\nimport json\nimport os\nimport runpy\nimport sys\nimport traceback\n\nclass NoopContextManager:\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\nclass ErrorHandlerContextManager:\n    def __init__(self, inner_cm):\n        self.inner_cm = inner_cm\n\n    def __enter__(self):\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__enter__(), 'UserExecution.context_manager.enter')\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value:\n            write_error('UserExecution.script', 'UserError', exc_value, 'NonCompliant')\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__exit__(exc_type, exc_value, traceback), 'UserExecution.context_manager.exit')\n\n    @staticmethod\n    def do_op_and_write_error(op, error_code):\n        try:\n            return op()\n        except Exception as e:\n            write_error(error_code, 'SystemError', e, 'Compliant')\n            raise\n\ndef write_error(code, category, error, compliant):\n    try:\n        error_path = os.environ.get('_AZUREML_CR_ERROR_JSON_FILE')\n        dir = os.path.dirname(error_path)\n        os.makedirs(dir, exist_ok=True)\n        with open(error_path, 'x') as f:\n            f.write(json.dumps(to_cr_error(code, category, error, compliant)))\n    except:\n        pass\n\ndef to_cr_error(code, category, error, compliant):\n    known_errors = [\n        'BaseException', 'SystemExit', 'KeyboardInterrupt', 'GeneratorExit', 'Exception', 'StopIteration', 'StopAsyncIteration',\n        'ArithmeticError', 'FloatingPointError', 'OverflowError', 'ZeroDivisionError', 'AssertionError', 'AttributeError',\n        'BufferError', 'EOFError', 'ImportError', 'ModuleNotFoundError', 'LookupError', 'IndexError', 'KeyError', 'MemoryError',\n        'NameError', 'UnboundLocalError', 'OSError', 'BlockingIOError', 'ChildProcessError', 'ConnectionError', 'BrokenPipeError',\n        'ConnectionAbortedError', 'ConnectionRefusedError', 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n        'InterruptedError', 'IsADirectoryError', 'NotADirectoryError', 'PermissionError', 'ProcessLookupError', 'TimeoutError',\n        'ReferenceError', 'RuntimeError', 'NotImplementedError', 'RecursionError', 'SyntaxError', 'IndentationError', 'TabError',\n        'SystemError', 'TypeError', 'ValueError', 'UnicodeError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeTranslateError',\n        'Warning', 'DeprecationWarning', 'PendingDeprecationWarning', 'RuntimeWarning', 'SyntaxWarning', 'UserWarning',\n        'FutureWarning', 'ImportWarning', 'UnicodeWarning', 'BytesWarning', 'EncodingWarning', 'ResourceWarning', 'IOError',\n        'EnvironmentError'\n    ]\n    exc_type, exc_val, exc_traceback = sys.exc_info()\n    stack_trace = ''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback))\n    exception_type = type(error).__name__\n    known_error = exception_type in known_errors\n    exception_type_compliance = 'Compliant' if known_error else compliant\n\n    cr_error = {\n        'code': code,\n        'category': category,\n        'message': { compliant: str(error) },\n        'details': [\n            {\n                'name': 'StackTrace',\n                'value': { compliant: stack_trace }\n            },\n            {\n                'name': 'ExceptionType',\n                'value': { exception_type_compliance: exception_type }\n            },\n        ]\n    }\n\n    try:\n        from azureml.exceptions import AzureMLException, UserErrorException\n        if isinstance(error, UserErrorException):\n            cr_error['category'] = 'UserError'\n        if isinstance(error, AzureMLException):\n            cr_error['details'][1]['value'] = { 'Compliant': exception_type }\n    except:\n        pass\n\n    return cr_error\n\n# Copied from context manager injector\ndef strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback):\n    \"\"\"\n        The actual traceback that gets printed when the exception is in the user code is:\n\n        Traceback(most recent call last) :\n            File 'azureml-setup/context_manager_injector.py', line 161, in <module>\n                execute_with_context(cm_objects, options.invocation)\n            File 'azureml-setup/context_manager_injector.py', line 91, in execute_with_context\n                runpy.run_path(sys.argv[0], globals(), run_name= '__main__')\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 263, in run_path\n                pkg_name = pkg_name, script_name = fname)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 96, in _run_module_code\n                mod_name, mod_spec, pkg_name, script_name)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 85, in _run_code\n                exec(code, run_globals)\n            File 'bad_import.py', line 5, in <module>\n                import thisdoesnotexist\n        ModuleNotFoundError: No module named 'thisdoesnotexist'\n\n        however we strip the first 5 layers to give the user a traceback that only contains the user code as part of it\n    \"\"\"\n    traceback_as_list = traceback.format_exception(exc_type, exc_val, exc_traceback)\n    reversed_traceback_list = reversed(traceback_as_list)\n    reversed_trimmed_stack = []\n    # currently the innermost runpy stack occurs inside runpy.py in _run_code and inside the exec(code, run_globals) function\n    # if that changes then the regular stack will be printed\n    keywords_in_innermost_runpy_stack_frame = ['runpy.py', '_run_code', 'exec(code, run_globals)']\n    error_is_in_user_code = False\n    for stack_frame in reversed_traceback_list:\n        if all([keyword in stack_frame for keyword in keywords_in_innermost_runpy_stack_frame]):\n            error_is_in_user_code = True\n            break\n        reversed_trimmed_stack.append(stack_frame)\n    if error_is_in_user_code:\n        # Find the first index of 'Traceback (most recent call last):' in reversed list and append the cause exceptions\n        # This will handle users using 'from with raise' when raising exception\n        reversed_traceback_as_list = traceback_as_list[::-1]\n        traceback_indexes = [idx for idx,stack_frame in enumerate(reversed_traceback_as_list)\n                             if 'Traceback (most recent call last):' in stack_frame]\n        if len(traceback_indexes) > 0:\n            reversed_trimmed_stack.extend(reversed_traceback_as_list[traceback_indexes[0]:])\n\n    return list(reversed(reversed_trimmed_stack))\n\ndef main():\n    # This used to be done in a context_managers.py and context_manager_injector.py where it will add current working\n    # directory and the script's directory to sys.path respectively.\n    # We want to make sure the script's directory is added to the start of sys.path so that it is searched\n    # first and the current working directory is added to the end so that it is searched last.\n    sys.path.insert(0, os.path.dirname(os.path.abspath(sys.argv[1])))\n    sys.path.append(os.getcwd())\n\n    try:\n        import logging\n        from azureml._async import WorkerPool\n        from azureml.core import Run\n        from azureml.history._tracking import get_azureml_logger, get_process_name\n\n        # Only do this check if AzureML is used\n        if sys.version_info.major != 3 or sys.version_info.minor < 5:\n            raise RuntimeError(f'Python version {str(sys.version_info)} is not supported. Please use python>=3.5')\n\n        aml_logger, azureml_log_file_path = get_azureml_logger(get_process_name())\n        worker_pool = WorkerPool(_ident='HistoryTrackingWorkerPool', _parent_logger=aml_logger)\n\n        # We are explicitly NOT setting used_for_context_manager to True. Setting it to True will just create an instance of _SubmittedRun\n        # instead of saving it to the _SubmittedRun.__instances dictionary. When it is saved to the dictionary, the instance will be\n        # shared when the user wants to use the Run to log metrics and it will use the same instance as the one we have now so\n        # we can actually make sure the metrics are flushed correctly.\n        context = Run.get_context(_worker_pool=worker_pool, allow_offline=False, redirect_output_stream=False)._client.metrics\n    except ImportError:\n        context = NoopContextManager()\n    except RuntimeError:\n        raise\n    except Exception as e:\n        print(f'Warning: Failed to setup Azure Machine Learning system code due to `{e}`. Your job will proceed but if you notice any issues, please contact Azure Support with this exception message.', file=sys.stderr)\n        context = NoopContextManager()\n\n    context = ErrorHandlerContextManager(context)\n    with context:\n        # when we invoke with `python -c program args`, sys.argv[0] will be -c, args will be the rest (i.e. sys.argv[1:])\n        sys.argv = sys.argv[1:]\n        runpy.run_path(sys.argv[0], globals(), run_name='__main__')\n\nif __name__ == '__main__':\n    try:\n        main()\n    except SystemExit as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        if ex.code is not None:\n            sys.exit(ex.code)\n        else:\n            sys.exit(1)\n    except Exception as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        sys.exit(1)\n", "train-lgb.py", "--input-data", "d2c5cd9f-993a-4027-865e-8bb2b68caafb"]) }), stderr: None, stdout: Some("user_logs/std_log.txt") }) execution_env_f=ExecutionEnvironment { env_vars: {"AZUREML_CR_HT_CAP_logs_PATH": "/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/exe/wd/logs", "AZUREML_CR_CS_CAPABILITY_RUNNING": "TRUE", "AZUREML_CR_HT_CAP_outputs_PATH": "/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/exe/wd/outputs", "AZUREML_CR_HT_CAP_azureml_logs_PATH": "/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/exe/wd/azureml-logs", "AZUREML_CR_HOSTTOOLS_CAPABILITY_RUNNING": "TRUE", "AZUREML_CR_HT_CAP_user_logs_PATH": "/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/exe/wd/user_logs"}, path_mappings: {} }}: lifecycler::executor_client: Starting execution execution_id=73488e0c-fcd1-42ba-9225-c11e14d8c4e0
2022-01-18T13:45:35.007937Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands:executor_client::start_execution{commands_f=Command(Command { executable: Spawn(Spawn { program: "/azureml-envs/azureml_08f74657c3f2d3647b16ec4c255a28d8/bin/python", args: Some(["-c", "\nimport json\nimport os\nimport runpy\nimport sys\nimport traceback\n\nclass NoopContextManager:\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\nclass ErrorHandlerContextManager:\n    def __init__(self, inner_cm):\n        self.inner_cm = inner_cm\n\n    def __enter__(self):\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__enter__(), 'UserExecution.context_manager.enter')\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value:\n            write_error('UserExecution.script', 'UserError', exc_value, 'NonCompliant')\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__exit__(exc_type, exc_value, traceback), 'UserExecution.context_manager.exit')\n\n    @staticmethod\n    def do_op_and_write_error(op, error_code):\n        try:\n            return op()\n        except Exception as e:\n            write_error(error_code, 'SystemError', e, 'Compliant')\n            raise\n\ndef write_error(code, category, error, compliant):\n    try:\n        error_path = os.environ.get('_AZUREML_CR_ERROR_JSON_FILE')\n        dir = os.path.dirname(error_path)\n        os.makedirs(dir, exist_ok=True)\n        with open(error_path, 'x') as f:\n            f.write(json.dumps(to_cr_error(code, category, error, compliant)))\n    except:\n        pass\n\ndef to_cr_error(code, category, error, compliant):\n    known_errors = [\n        'BaseException', 'SystemExit', 'KeyboardInterrupt', 'GeneratorExit', 'Exception', 'StopIteration', 'StopAsyncIteration',\n        'ArithmeticError', 'FloatingPointError', 'OverflowError', 'ZeroDivisionError', 'AssertionError', 'AttributeError',\n        'BufferError', 'EOFError', 'ImportError', 'ModuleNotFoundError', 'LookupError', 'IndexError', 'KeyError', 'MemoryError',\n        'NameError', 'UnboundLocalError', 'OSError', 'BlockingIOError', 'ChildProcessError', 'ConnectionError', 'BrokenPipeError',\n        'ConnectionAbortedError', 'ConnectionRefusedError', 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n        'InterruptedError', 'IsADirectoryError', 'NotADirectoryError', 'PermissionError', 'ProcessLookupError', 'TimeoutError',\n        'ReferenceError', 'RuntimeError', 'NotImplementedError', 'RecursionError', 'SyntaxError', 'IndentationError', 'TabError',\n        'SystemError', 'TypeError', 'ValueError', 'UnicodeError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeTranslateError',\n        'Warning', 'DeprecationWarning', 'PendingDeprecationWarning', 'RuntimeWarning', 'SyntaxWarning', 'UserWarning',\n        'FutureWarning', 'ImportWarning', 'UnicodeWarning', 'BytesWarning', 'EncodingWarning', 'ResourceWarning', 'IOError',\n        'EnvironmentError'\n    ]\n    exc_type, exc_val, exc_traceback = sys.exc_info()\n    stack_trace = ''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback))\n    exception_type = type(error).__name__\n    known_error = exception_type in known_errors\n    exception_type_compliance = 'Compliant' if known_error else compliant\n\n    cr_error = {\n        'code': code,\n        'category': category,\n        'message': { compliant: str(error) },\n        'details': [\n            {\n                'name': 'StackTrace',\n                'value': { compliant: stack_trace }\n            },\n            {\n                'name': 'ExceptionType',\n                'value': { exception_type_compliance: exception_type }\n            },\n        ]\n    }\n\n    try:\n        from azureml.exceptions import AzureMLException, UserErrorException\n        if isinstance(error, UserErrorException):\n            cr_error['category'] = 'UserError'\n        if isinstance(error, AzureMLException):\n            cr_error['details'][1]['value'] = { 'Compliant': exception_type }\n    except:\n        pass\n\n    return cr_error\n\n# Copied from context manager injector\ndef strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback):\n    \"\"\"\n        The actual traceback that gets printed when the exception is in the user code is:\n\n        Traceback(most recent call last) :\n            File 'azureml-setup/context_manager_injector.py', line 161, in <module>\n                execute_with_context(cm_objects, options.invocation)\n            File 'azureml-setup/context_manager_injector.py', line 91, in execute_with_context\n                runpy.run_path(sys.argv[0], globals(), run_name= '__main__')\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 263, in run_path\n                pkg_name = pkg_name, script_name = fname)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 96, in _run_module_code\n                mod_name, mod_spec, pkg_name, script_name)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 85, in _run_code\n                exec(code, run_globals)\n            File 'bad_import.py', line 5, in <module>\n                import thisdoesnotexist\n        ModuleNotFoundError: No module named 'thisdoesnotexist'\n\n        however we strip the first 5 layers to give the user a traceback that only contains the user code as part of it\n    \"\"\"\n    traceback_as_list = traceback.format_exception(exc_type, exc_val, exc_traceback)\n    reversed_traceback_list = reversed(traceback_as_list)\n    reversed_trimmed_stack = []\n    # currently the innermost runpy stack occurs inside runpy.py in _run_code and inside the exec(code, run_globals) function\n    # if that changes then the regular stack will be printed\n    keywords_in_innermost_runpy_stack_frame = ['runpy.py', '_run_code', 'exec(code, run_globals)']\n    error_is_in_user_code = False\n    for stack_frame in reversed_traceback_list:\n        if all([keyword in stack_frame for keyword in keywords_in_innermost_runpy_stack_frame]):\n            error_is_in_user_code = True\n            break\n        reversed_trimmed_stack.append(stack_frame)\n    if error_is_in_user_code:\n        # Find the first index of 'Traceback (most recent call last):' in reversed list and append the cause exceptions\n        # This will handle users using 'from with raise' when raising exception\n        reversed_traceback_as_list = traceback_as_list[::-1]\n        traceback_indexes = [idx for idx,stack_frame in enumerate(reversed_traceback_as_list)\n                             if 'Traceback (most recent call last):' in stack_frame]\n        if len(traceback_indexes) > 0:\n            reversed_trimmed_stack.extend(reversed_traceback_as_list[traceback_indexes[0]:])\n\n    return list(reversed(reversed_trimmed_stack))\n\ndef main():\n    # This used to be done in a context_managers.py and context_manager_injector.py where it will add current working\n    # directory and the script's directory to sys.path respectively.\n    # We want to make sure the script's directory is added to the start of sys.path so that it is searched\n    # first and the current working directory is added to the end so that it is searched last.\n    sys.path.insert(0, os.path.dirname(os.path.abspath(sys.argv[1])))\n    sys.path.append(os.getcwd())\n\n    try:\n        import logging\n        from azureml._async import WorkerPool\n        from azureml.core import Run\n        from azureml.history._tracking import get_azureml_logger, get_process_name\n\n        # Only do this check if AzureML is used\n        if sys.version_info.major != 3 or sys.version_info.minor < 5:\n            raise RuntimeError(f'Python version {str(sys.version_info)} is not supported. Please use python>=3.5')\n\n        aml_logger, azureml_log_file_path = get_azureml_logger(get_process_name())\n        worker_pool = WorkerPool(_ident='HistoryTrackingWorkerPool', _parent_logger=aml_logger)\n\n        # We are explicitly NOT setting used_for_context_manager to True. Setting it to True will just create an instance of _SubmittedRun\n        # instead of saving it to the _SubmittedRun.__instances dictionary. When it is saved to the dictionary, the instance will be\n        # shared when the user wants to use the Run to log metrics and it will use the same instance as the one we have now so\n        # we can actually make sure the metrics are flushed correctly.\n        context = Run.get_context(_worker_pool=worker_pool, allow_offline=False, redirect_output_stream=False)._client.metrics\n    except ImportError:\n        context = NoopContextManager()\n    except RuntimeError:\n        raise\n    except Exception as e:\n        print(f'Warning: Failed to setup Azure Machine Learning system code due to `{e}`. Your job will proceed but if you notice any issues, please contact Azure Support with this exception message.', file=sys.stderr)\n        context = NoopContextManager()\n\n    context = ErrorHandlerContextManager(context)\n    with context:\n        # when we invoke with `python -c program args`, sys.argv[0] will be -c, args will be the rest (i.e. sys.argv[1:])\n        sys.argv = sys.argv[1:]\n        runpy.run_path(sys.argv[0], globals(), run_name='__main__')\n\nif __name__ == '__main__':\n    try:\n        main()\n    except SystemExit as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        if ex.code is not None:\n            sys.exit(ex.code)\n        else:\n            sys.exit(1)\n    except Exception as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        sys.exit(1)\n", "train-lgb.py", "--input-data", "d2c5cd9f-993a-4027-865e-8bb2b68caafb"]) }), stderr: None, stdout: Some("user_logs/std_log.txt") }) execution_env_f=ExecutionEnvironment { env_vars: {"AZUREML_CR_HT_CAP_logs_PATH": "/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/exe/wd/logs", "AZUREML_CR_CS_CAPABILITY_RUNNING": "TRUE", "AZUREML_CR_HT_CAP_outputs_PATH": "/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/exe/wd/outputs", "AZUREML_CR_HT_CAP_azureml_logs_PATH": "/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/exe/wd/azureml-logs", "AZUREML_CR_HOSTTOOLS_CAPABILITY_RUNNING": "TRUE", "AZUREML_CR_HT_CAP_user_logs_PATH": "/mnt/azureml/cr/j/71c0e7a978814dd5982dcdccd674025c/exe/wd/user_logs"}, path_mappings: {} }}: lifecycler::executor_client: close time.busy=180µs time.idle=3.45ms
2022-01-18T13:45:35.007961Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands: lifecycler::executor_client: Waiting for execution completion execution_id="73488e0c-fcd1-42ba-9225-c11e14d8c4e0"
2022-01-18T13:45:54.789045Z  INFO LifecycleServicer::complete_execution: grpc_utils::server: Got grpc request name="complete_execution" remote_addr=None
2022-01-18T13:45:54.789111Z  INFO LifecycleServicer::complete_execution: lifecycler::service: close time.busy=76.9µs time.idle=13.4µs
2022-01-18T13:45:54.789133Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands:executor_client::wait_for_execution_completion{execution_id="73488e0c-fcd1-42ba-9225-c11e14d8c4e0"}: lifecycler::executor_client: close time.busy=5.40µs time.idle=19.8s
2022-01-18T13:45:54.789155Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands: lifecycler::executor_client: Execution completed execution_id="73488e0c-fcd1-42ba-9225-c11e14d8c4e0"
2022-01-18T13:45:54.789197Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands: lifecycler::executor_client: close time.busy=580µs time.idle=19.8s
2022-01-18T13:45:54.789224Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: phase execution completed. rank=None phase=0
2022-01-18T13:45:54.789269Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: close time.busy=1.35ms time.idle=19.8s
